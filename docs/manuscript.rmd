---
title: Towards the construction of a causal map of the human phenome
author: Gibran Hemani, Jie Zheng, Philip Haycock, Jack Bowden, Tom Gaunt, George Davey Smith
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document:
    fig_caption: yes
    keep_tex: true
  word_document: default
header-includes:
   - \usepackage{amsmath}
bibliography: manuscript.bib
csl: vancouver.csl
---

## Abstract

A major application for genome-wide association studies (GWAS) has been the emerging field of causal inference using Mendelian randomisation (MR), where the causal effect between a pair of traits can be estimated using only summary level data. MR depends on SNPs exhibiting vertical pleiotropy, where the SNP influences an outcome phenotype only through an exposure phenotype. Issues arise when this assumption is violated due to SNPs exhibiting horizontal pleiotropy, and many methods have been developed in an attempt to address this. Here we show that the mechanisms that underlie horizontal pleiotropy are numerous, and that instrument selection will be increasingly liable to selecting invalid instruments as GWAS sample sizes continue to grow. We have developed a mixture of experts machine learning approach (MR-MoE 1.0) that improves on both power and false discovery rates over all existing methods. Using the approach, we systematically estimated the causal effects amongst 2407 phenotypes, generating a draft of the causal map of the human phenome. But we offer caution that its interpretation is far from straightforward.


## Introduction

Mendelian randomisation (MR) [@DaveySmith2003; @DaveySmithHemani2014] exploits genetic pleiotropy to infer the causal relationships between phenotypes. Suppose that one trait (the exposure) causally influences another (the outcome). If a SNP influences the outcome through the exposure then the SNP is exhibiting vertical pleiotropy. Such a genetic variant is considered to be an instrumental variable for the exposure, and can be exploited to mimic a randomised controlled trial, enabling a causal estimate to be made by comparing the outcome phenotypes between those individuals that have the exposure-increasing allele against those who do not. Multiple independent genetic variants for a particular exposure can be used jointly to improve causal inference, because a) each variant represents an independent natural experiment, and an overall causal estimate can be obtained by meta-analysing the single estimates from each instrument; and b) some violations of the assumptions of MR (most notably that the SNP influences the outcome through no pathways other than the exposure) can be evaluated through sensitivity analyses [@Bowden2015; @Bowden2016b; @Bowden2017; @Hartwig2017; @Hemani2017].

Genome-wide association studies (GWAS) have identified genetic instrumental variables for thousands of phenotypes [@Hindorff2010]. Recent developments in Mendelian randomisation have enabled knowledge of instrumental variables to be applied using only summary level data (known as two-sample MR, 2SMR) [@Pierce2013]. Here, in order to infer the causal effect of an exposure on an outcome all that is required is an estimate of the genetic effects of the instrumenting SNP on the exposure, and the corresponding estimate of the effect on the outcome. This has two major advantages. First, GWAS summary data is non-disclosive and often publicly available. Second, causal inference can be made between phenotypes even if they have not been measured in the same samples, limiting the breadth of possible causal estimates only to the availability of GWAS summary data for the traits in question [@Hemani2016].

Problems with obtaining unbiased causal effects can arise, however, if the genetic instruments exhibit horizontal pleiotropy (HP), where they influence the outcome through a pathway other than the exposure. The extent of this phenomenon is not to be understated, and many methods have been developed that attempt to reliably obtain unbiased causal estimates under specific models of HP [@Bowden2015; @Bowden2016b; @Bowden2017; @Hartwig2017]. It is considered best practice to report estimates from all available methods as sensitivity analyses when presenting causal estimates, however this strategy is not necessarily optimal for several reasons. First, if different methods disagree it is not possible to know which is correct because the true nature of HP exhibited by the instruments is not known. Second, though the IVW approach is most statistically powerful under no HP, it can have high false negative or low true positive rates in the presence of HP compared to other methods. Given that pleiotropy has been hypothesised to be universal [@Wagner2011; @Hill2012a], defaulting to the IVW method in the first instance and using other methods as sensitivity analyses may not be appropriate. Third, the available methods do not cover all possible models of HP, and therefore an automated method for instrument selection may be necessary. Fourth, it could be of interest to make causal effect estimates for thousands of traits, in which case a discerning evaluation of each causal effect of interest may not be possible or convenient.

In this paper we introduce two innovations towards improving the reliability of MR estimates. First, we introduce an approach to discard genetic variants that are likely to be invalid. Second, we hypothesised that characteristics of the summary data could indicate which method would be most reliable, and we introduce new machine learning approaches that attempt to automate both instrument and method selection. Using curated GWAS summary data for thousands of phenotypes [@Hemani2016], we use these new methods to construct a graph of millions of causal estimates. We consider this to be a 'first draft' of the causal map of the human phenome, but raise caution throughout that its interpretation is far from straightforward


## Methods

### GWAS summary data and their use in 2SMR

The use of summary data in two-sample MR is described in detail elsewhere [@Hemani2016]. A brief outline of the procedure is as follows. First, genetic instruments for the exposure trait need to be identified - those SNPs with $p < 10^{-8}$ are retained in order to ensure that the first assumption of Mendelian randomisation (that the instrument associates with the exposure) is satisfied. We collect their effect sizes, standard errors and effect alleles for the association with the exposure trait. These can be obtanied manually from complete summary data or from curated lists of significant GWAS associations. Next, the effects of those SNPs on the outcome need to be obtained, typically necessitating complete summary data because it is unlikely that these SNPs will have reached genome-wide significance (and therefore be present in curated catalogues). At its most simple implementation, the regression of the SNP-exposure effect sizes against the SNP-outcome effect sizes, with greater weight afforded to those SNPs with smaller SNP-outcome standard errors, provides the estimate of the causal effect of the exposure on the outcome. This is known as the inverse-variance weighted (IVW) method.

Given summary data for a large number of traits, it is straightforward to exhaustively analyse the causal relationships of every trait against every other trait for which there is sufficient summary data available. Supplementary table 1 provides a list of all traits that have available GWAS summary data, indicating if they have complete summary data (in which case they can be used as both exposure traits and outcome traits), or if they only have significant associations (in which they can only be used as exposure traits). 


### Mendelian randomisation methods and their assumptions

In this paper we consider three main classes of MR estimation. Full details for each approach have been described extensively elsewhere.

**Mean-based methods:** Here we consider four nested models [@Bowden2017]. The inverse variance weighted (IVW) fixed effects meta-analysis approach assumes that variants exhibit no HP. IVW random effects meta-analysis relaxes the HP assumption, allowing it to be present but balanced - such that it only leads to increased heterogeneity around the regression and not introducing bias. Fixed effects Egger regression [@Bowden2015] relaxes the HP assumption further by allowing a non-zero intercept which essentially allows horizontal pleiotropy to be directional, where it systematically influences the outcome in a specific direction. Random effects Egger regression allows heterogeneity around the directional HP, as long as the HP effects are not correlated with the SNP-exposure effects (also known as the INSIDE assumption). 

The Rucker framework [@Rucker2011], adapted to MR [@Bowden2017] uses estimates of heterogeneity in the IVW and Egger frameworks to navigate between these nested models. A jackknife approach (random selection with replacement of instruments) can be used to obtain a sampling distribution for the model estimate amongst these four variations. Using 1000 rounds of jackknife estimates, we can obtain a final estimate using the mean or the median of the distribution. We only use the jackknife approach for associations where there are 15 or more variants to avoid combinatorial saturation. The four nested models plus the three Rucker estimates provide seven mean based estimators.

**Median-based methods:** An alternative approach is to take the median effect of all available instruments [@Bowden2016b]. This has the advantage that up to half the instruments can be invalid, and the estimate will remain unbiased. Developing the approach further to allow stronger instruments to contribute more towards the estimate can be obtained by obtaining the median of the weights of each instrument. The penalised weighted median estimator introduces a further weight to the instruments, penalising any instrument that contributes substantially towards the heterogeneity statistic. Together, this provides three median based estimators.

**Mode-based methods:** Similar to the median, the mode based estimator clusters the instruments into groups based on similarity of causal effects, and returns the final causal effect estimate based on the cluster that has the largest number of instruments [@Hartwig2017]. This can be extended in two ways, first by weighting the strength of each cluster by the inverse of the variance of the SNP-outcome associations in the cluster; second by weighting the strength of each cluster by the inverse of the variance of the SNP-exposure associations. When weighting by the SNP-outcome standard errors we term this a weighted analysis. When *not* weighting by the exposure standard errors we term this the 'no measuremenent error in the exposure (NOME)' assumption. Together this provides four mode-based estimators.


### Instrument selection

#### Top hits

The simplest approach to selecting instruments for performing MR is to take take SNPs that have been declared significant in the published GWAS for the exposure. This typically involves obtaining SNPs that surpass $p < 5 \times 10^{-8}$, using clumping to obtain independent SNPs, and then replicating in an independent sample. These results are often recorded in public GWAS catalogs. Alternatively the clumping procedure can be performed using complete summary data in MR-Base. We call this the "top hits" strategy.


#### Steiger filtering

With genome-wide association studies growing ever larger, the statistical power to detect significant associations that may be influencing the trait downstream of many other pathways increases. For example, if a SNP $g_{A}$ influences trait $A$, and trait $A$ influences trait $B$, then a sufficiently powered GWAS will identify the $g_{A}$ as being significant for trait $B$ (Figure 1a). Using $g_{A}$ as an instrument to test the causal effect of $A$ on $B$ is perfectly valid. But in the (incorrectly hypothesised) MR analysis of trait $B$ on trait $A$ could erroneously result in the apparent causal association of $B$ on $A$. If $g_{A}$ is only one of many known instruments for $B$, amongst which some are valid, it is to the advantage of the researcher to exclude $g_{A}$ from the analysis. 

An approach to inferring the causal direction between phenotypes was developed recently [@Hemani2017], using the following basic premise. If trait $A$ causes trait $B$ then 

$$
\sum^M_{i=1}{cor(g_{i}, A)^2} > \sum^M_{i=1}{cor(g_{i}, B)^2}
$$

because the $cor(g_{i}, B)^2 = cor(A, B)^{2} cor(g_{i}, A)^{2}$. This simple inequality will not hold in some cases, for example $\rho_{x, x_o} < \rho_{x,y}\rho_{y,y_o}$ where $\rho_{x, x_o}$ and $\rho_{y, y_o}$ are the precision of the measurements of the $x$ and $y$. Some combinations of confounding effects can also distort the $\rho_{g,x}$ and $\rho_{g,y}$ parameters, as has been discussed in detail previously. However, we use it here as an inexpensive and approximate method to identify variants that are likely to be invalid. Steiger's Z-test of correlated correlations [@Steiger1980] can be used to formally test the extent to which the two correlations are statistically different.

Here we adapt this approach to automatically filter SNPs that are liable to be invalid (Figure 1a). In this case the Steiger test applied to each variant in turn and we exclude any $g_{A}$ for which the Steiger Z-test has $p > 0.05$, indicating that it is unlikely to primarily associate with $B$ relative to $A$. Similarly, for SNPs that influence confounders of $A$ and $B$ or those variants that exhibit horizontal pleiotropy, the difference in $cor(g_{i}, A)^2$ and $cor(g_{i}, B)^2$ will be reduced, increasing the likelihood of the SNP being excluded because the Steiger Z-test is less likely to be significant.

To estimate $cor(g, x)^2$, if $x$ is continuous we obtain the F-statistic from the reported p-value and sample size and then $cor(g, x)^2 = \frac{F}{N - 2 - F}$. If $x$ is binary then we estimate the variance of the underlying liability explained by the SNP, $cor(g, x)^2 = \frac{V_a}{V_a + V_e}$. Here, $V_e = \pi^2/3$, and $V_a = 2\beta^2p(1-p)$, where $\beta$ is the log odds ratio and $p$ is the allele frequency of the SNP in the population [@Lee2013c]. $p$ can be estimated using the allele frequency of the SNP in an ascertained sample by deriving the $2 \times 2$ contingency table from the odds ratio $e^\beta$, allele frequency in the ascertained sample $p_{cc}, and number of cases $N_1$ and controls $N_0$.

### Competitive mixture of experts

We consider the 14 MR methods described above, for which instruments can be supplied using two instrument selection strategies, leading to 28 methods in total. In the context of this analysis, each method is considered to be an 'expert', taking a set of SNP-exposure and SNP-outcome effect sizes and their standard errors as inputs. Our objective is to select the expert most likely to be correct for a specific MR analysis. 

The mixture of experts method is a machine learning approach [@Jordan1994] which seeks to divide a parameter space into subdomains, such that a particular expert is used primarily for problems that reside in a subdomain most suited to that expert. In this case our objective is to identify characteristics of the SNP-exposure and SNP-outcome associations for which one specific MR method is most likely to yield highest statistical power for non-null associations, and lowest false discovery rates for null associations. This involves creating a 'gating function', whose purpose is to decide which expert to use for a specific MR analysis, given the parameter space that is occupied by that dataset. The metrics are a mixture of regression diagnostics and are described in Supplementary table 2.

The gating function needs to be trained using data for which the true causal effect is known, and to this end we generated a large number of simulated datasets. We trained the gating function using random forest learning algorithms that seek to identify sectors of the parameter space that are most likely to return accurate estimates for a particular expert. Figure 2a illustrates how the gating function is trained using simulated data. New datasets can then be applied to the trained mixture of experts (MoE) model (Figure 2b). There are countless ways to implement this approach, we call this implementation MR-MoE 1.0. 


**Training and testing simulations**

The MoE is trained using datasets generated from simulations (Figure 2a). A *dataset* is the minimum data required to perform 2SMR analysis - four columns comprising the SNP-exposure and SNP-outcome effects and standard errors, and rows corresponding to each SNP that is used as an instrument for the exposure. This *dataset* can be fed into any of the 28 experts to obtain MR causal effects. The simulations used to generate these datasets seek to cover a range of pleiotropic scenarios, including where some proportion of SNPs exhibit directional or balanced horizontal pleiotropy, or where SNPs influencing confounding variables.

We simulate two individual level datasets for which there are $N_x$ and $N_y$ samples, and $M$ SNPs, where each SNP has effect allele frequency of $p_m \sim U(0.05, 0.95)$. These datasets are used to obtain the SNP effects for the exposure trait $x$ and the outcome trait $y$, respectively, using the following sampling criteria:

$$
\begin{aligned}
N_x & = \{20000, ..., 500000\} \\
N_y & = \{20000, ..., 500000\} \\
K & = \{0, ..., 10\} \\
M_x & = \{1, ..., 200\} \\
M_y & = \{1, ..., 200\} \\
M_{u_k} & = \{5,..., 30\} \\
\end{aligned}
$$

The $M = M_x + M_y + \sum{M_{u_k}}$ SNPs can influence $x$ directly, $y$ directly, or some number of confounders $u_{k}$ directly. Phenotypes for $x$ and $y$ are constructed using

$$
x = \sum^{M_x}_{i}{\beta_{gx,x,i}g_{x,i}} + \sum^{M_y}_{j}{\beta_{gy,x,j}g_{y,j}} + \sum^{K}_{k}{\beta_{ux,k} u_{k}} + e_{x}
$$

where $\beta_{gx,x}$ is the vector of effects of each of the $M_x$ SNPs that influence $x$ primarily, $\beta_{gy,x}$ is the vector of effects for the $M_y$ SNPs on $x$, where the $M_y$ SNPs influence $y$ primarily but exhibit horizontal pleiotropic effects on $x$. We allow some proportion of these effects to be 0. $\beta_{ux}$ is the vector of effects of each of the $K$ confounders on $x$. Each $u_{k}$ variable is constructed using

$$
u = \sum^{M_u}_{l}{\beta_{gu,l}g_{l}} + e_{l}
$$

and finally $y$ is constructed using

$$
y = \beta_{x,y}x + \sum^{M_y}_{i}{\beta_{gy,y,j}g_{y,j}} + \sum^{M_x}_{j}{\beta_{gx,y,i}g_{x,i}} + \sum^{K}_{k}{\beta_{uy,k} u_{k}} + e_{y}
$$

where $\beta_{x,y}$ is the causal effect of $x$ on $y$. We sample the distribution of direct SNP effects using

$$
\begin{aligned}
\beta_{gx,x,i} & \sim N(0, \sigma^2_{gx,x}) \\
\sigma^2_{gx,x,i} & \sim U(0.01, 0.1) \\
\beta_{gy,y,j} ~ N(0, \sigma^2_{gy,y}) \\
\sigma^2_{gy,y,j} & \sim U(0.01, 0.1) \\
\end{aligned}
$$

Some proportion $s_x \sim U(0,1)$ of $g_x$ SNPs and some proportion $s_y \sim U(0,1)$ of $g_y$ SNPs exhibit horizontal pleiotropy with effects sampled using

$$
\begin{aligned}
\beta_{gx,y,i*} & \sim N(\mu_{gx,y}, \sigma^2_{gx,y})  \\
\mu_{gx,y,i*} & \sim U(-0.005, 0.005) \\
\sigma^2_{gx,y,i*} & \sim U(0.001, 0.01) \\
\beta_{gy,x,j*} & \sim N(\mu_{gy,x}, \sigma^2_{gy,x}) \\
\mu_{gy,x,j*} & \sim U(-0.005, 0.005) \\
\sigma^2_{gy,x,j*} & \sim U(0.001, 0.01) \\
\end{aligned}
$$

The genetic influences on each of the confounders are sampled using

$$
\begin{aligned}
\beta_{gu,u,l} & \sim N(0, \sigma^2_{gu,u}) \\
\sigma^2_{gu,u,l} & \sim U(0.01, 0.1) \\
\end{aligned}
$$

The influence of each confounder on $x$ and $y$ is obtained using

$$
\begin{aligned}
\beta_{u,x} & \sim N(0, \sigma^{2}_{u,x}) \\
\beta_{u,y} & \sim N(0, \sigma^{2}_{u,y}) \\
\end{aligned}
$$

Finally, 20% of the simulations have a null effect of $\beta_{x,y} = 0$, while the other remaining 80% have a true effect sampled from

$$
\begin{aligned}.
\beta_{x,y} & \sim N(0, \sigma^2_{x,y}) \\
\sigma^2_{x,y} & \sim U(0.001, 0.1) \\
\end{aligned}
$$

For each simulation we used linear regression to estimate the genetic effect of each SNP $M$ on $x$ in sample 1, and each SNP $M$ on $y$ in sample 2. We then perform MR analysis in both directions, retaining SNPs that have $p < 5e-8$ in sample 1 to perform MR of $x$ on $y$ (the true causal direction for non-null simulations), and retaining SNPs that have $p < 5e-8$ in sample 2 to perform MR of $y$ on $x$ (the reverse causal direction for non-null simulations). We treat the summary data (effect sizes and standard errors) used for estimating $x \rightarrow y$ the summary data used for estimating $y \rightarrow x$ as two separate datasets Hence, for each simulation two datasets are generated which are analysed to produce 28 MR estimates each. We performed 100,000 simulations using these parameters, resulting in 200,000 datasets.

**Optimisation function**

We aim to maximise statistical power for datasets where $\beta_{x,y} \neq 0$ and minimise false discovery rates for datasets where $\beta_{x,y} = 0$. To train random forest decision trees to predict performance for a particular method $h(O_{w,d}, \textbf{z}_{d}$ is generated where the training set of input metrics for dataset $d$ is $\textbf{z}_{d}$ and the response (optimisation function) is

$$
    O_{w,d} = 
\begin{cases}
    1,   & \text{if } \beta_{x,y} \neq 0 \text{and } p_{m,d} < 0.01\\
    1,   & \text{if } \beta_{x,y} = 0 \text{and } p_{m,d} > 0.1 \\
    0,   & \text{otherwise}
\end{cases}
$$


**Strategy**

For each training dataset we record a set of 53 metrics $\textbf{z}_{d}$ (Supplementary table 2), and an outcome $O_{w,d}$, which is a measure of how well that method performed for each particular simulated dataset. For each of our 28 methods, we need to create a model that predicts the performance of the method based on metrics generated from a dataset. To do this, for each method we train random forest decision trees to predict that method's performance using the dataset's metrics. The random forest approach is well suited to this problem because there are likely to be non-continuous combinations of different metrics that improve on prediction over, for example, a simple linear model that does not learn about interactions. 

A simple hypothetical example - if a dataset has a single outlier but is otherwise exhibiting no heterogeneity then the following methods could arguably perform well:

- an IVW fixed effects analysis with the outlier removed, should the Steiger test be able to detect the outlier
- a median based approach
- a mode based approach

deciding between these methods requires finding, in general, which will minimise false discovery rates and maximise true positive rates for that particular scenario.

Having generated random forest decision trees for each of the 28 methods using 133,000 of the simulations, we then applied them to the remaining 67,000 datasets to predict which method would have the highest performance for each of the remaining datasets. Finally we compare the performance of the method selected by the MoE against all remaining methods. The default settings for the `randomForest` package in R [@Liaw2002] was used to train the models. MR-MoE 1.0 is implemented in the TwoSampleMR R package available at [github.com/MRCIEU/TwoSampleMR](https://github.com/MRCIEU/TwoSampleMR).


### Graph database of MR estimates

The set of MR estimates obtained from this analysis are recorded in a Neo4j graph database. Because each association has up to 28 different estimates, for simplicity we distill this down to a single 'best estimate' for each association using the following rules:

1. If the number of variants after Steiger filtering is greater than 5 then apply the MoE to obtain the best method
2. If the number of variants after Steiger filtering is less than or equal to 5 but greater than 1 then use the IVW random effects approach on the filtered set of variants
3. If there is 1 variant retained in the Steiger approach then use the Wald ratio on the remaining variant
4. If there are no variants remaining after Steiger filtering then declare no causal association.

For specific hypotheses we strongly recommend that estimates from all sensitivity analyses are scrutinised and reported. The graph can be queried directly using the cypher language at [http://shark.epi.bris.ac.uk:7474/browser/](http://shark.epi.bris.ac.uk:7474/browser/) or through a basic web interface at [http://shark.epi.bris.ac.uk:3838](http://shark.epi.bris.ac.uk:3838).


## Results

### Steiger filtering improves reliability

As statistical power for GWAS studies improves the likelihood of a significant association being discovered that doesn't act primarily on the trait of interest increases (Figure 1a). We evaluated the efficacy of the Steiger filtering approach for improving instrument selection using 100,000 simulated datasets comprising both null and non-null causal models. For each dataset, instruments were selected based on the tophits strategy and the Steiger filtering strategy, and MR was performed using 14 different methods based on instruments selected from each of these strategies.

Figure 1b shows that the tophits strategy led to over half of the instruments being primarily associated with either confounders or the outcome phenotype, not the exposure phenotype. The proportion of invalid instruments due to reverse cause increased as GWAS discovery sample size increased. Applying Steiger filtering reduced this to 25%. Consequently, the false discovery rates (FDR) for 12 of the 14 methods reduced substantially when applied using Steiger filtered instruments (Figure 1c). The true positive rates for the methods based on Steiger filtering did however reduce slightly for 10 of the 14 methods.


### Mixture of experts method selection improves over any single method

Following evidence that the Steiger filtering approach can improve on existing methods, we next hypothesised that a mixture of experts (MoE) model would be able to predict the most appropriate of the 28 MR methods and instrument selection strategies to apply to a particular dataset based on its characteristics (Figure 2). 

The ability to predict the performance for each of these methods is shown in Supplementary table 3, with prediction $R^2$ ranging between 0.04 and 0.24. The dataset characteristics with the most importance for each of the predictors differed substantially between each dataset, as well as the frequency for which each of the methods was selected in the testing datasets. The FDR of each method when chosen, compared to their averages across all datasets, reduced; and likewise the true positive rates of each method when chosen increased compared to their simulation-wide averages.

We compared the MoE performance in the simulations against each of the 28 methods, testing to see if it outperformed all other single methods. Figures 3a and 3b show that the MoE approach had the best general performance, obtaining an AUC of 0.84 in terms of classifying the simulations as being null or non-null. Notably, the next best methods were median and mode based estimators using Steiger filtering. Under the assumption of universal pleiotropy it is clear that all methods suffer from high false discovery rates.


### Automated MR analysis of 2407 phenotypes

We applied our analysis using summary data for 2407 phenotypes, including 149 complex traits and diseases, 575 metabolites [@Shin2014; @Kettunen2016] and 1683 plasma protein levels [@Sun2017]. For the protein levels only the instruments were available, so they could only be evaluated as exposure phenotypes. The complex traits and diseases and metabolite levels had complete summary data available in MR-Base, thus they be evaluated as both exposures (if they had significant instruments) and outcomes. Together, we evaluated 715681 relationships. The majority of these associations could only be evaluated using fewer than 5 SNPs, and so the Wald ratio or IVW fixed effects methods were used, but for 61029 associations the MR-MoE approach was applied.

There were 5660 associations following Bonferroni correction ($p < 7.0\times^{-8}$). Of these 2918 were obtained from the MR-MoE analysis, while the remainder were estimated using fewer than 5 SNPs using the Wald ratio or IVW fixed effects methods. 

The frequencies of the methods chosen by the MR-MoE analysis are shown in Supplementary table 2. Amongst those deemed 'significant', the IVW fixed effects analysis using tophits instruments (the only method applicable when there is no evidence of horizontal pleiotropy of any sort) was selected in only 10.4% of cases. 


### Causal associations involving years of schooling

As an example of the database, we performed a look up of associations that causally influence years of schooling [@Okbay2016], or that years of schooling itself causally influences. Using a false-discovery rate of 0.05, 45 traits were returned as having some direction of causality with years of schooling (Figure 4). Though many of these putative relationships appear to be plausible, it is clear that there are serious limitations to using MR as a panacea for causal inference. For example, bi-directional causal relationships with college completion exist because of the similarity in trait definitions; and there are several traits (e.g. childhood intelligence and birth weight) which appear to be causally downstream of years of schooling despite this being temporally impossible. The facility to perform these scans has been automated at the MR of everything vs everything (MR-EvE) website, [http://shark.epi.bris.ac.uk:3838](http://shark.epi.bris.ac.uk:3838), though we urge caution on interpretation of these findings.

## Discussion

The trend of increasing GWAS sample sizes continues, but while the opportunity that this affords MR to be furnished with more instruments is typically welcomed, here we have shown that it is invalid instruments, exhibiting horizontal pleiotropy or reverse causation, that are more likely to be identified than valid ones. Strategising how MR is to be used in practice, therefore, must consider horizontal pleiotropy to be the rule rather than the exception. Following a recent flurry in development of MR methodology, we have devised a machine learning approach, MR-MoE, that seeks to predict the performance of each MR method, selecting the one which is most likely to maximise power whilst minimising FDR for a specific dataset. The mixture of experts approach that we present here is trained using random forest decision trees applied to extensive and diverse simulations, and we demonstrate that it makes substantial performance improvements over any other single method in the presence or absence of extensive horizontal pleiotropy.

Crucially however, we observed in our simulations that none of the available methods were conservative and all, including MR-MoE, had FDR above 0.2. Instrumental variables in Mendelian randomisation are typically chosen blind, with GWAS significance being the only criteria. We illustrated how confounders and reverse causal associations can easily lead to invalid instruments being used in MR, and that even if those instruments that only influence the exposure directly are used, most randomly generated patterns of horizontal pleiotropy cannot be adequately accounted for by any single MR method.

We applied the method to the curated set of GWAS summary data present in MR-Base [@hemani2016mr], generating several million MR estimates. MR-MoE selected a method that indicated some pattern of horizontal pleiotropy for almost 90% of cases, reinforcing the notion that it is the rule rather than the exception. Based on our simulations we expect that those associations that we reported to be 'significant' are liable to high type 1 error rates. 

In addition to correctly handling horizontal pleiotropy, there are many other limitations that prevent MR from being a panacea for causal inference. Many of the associations are biologically impossible, for example where early life phenotypes appear to be influenced by later stage phenotypes. Though these associations can be informative, their interpretations as causal relationships are far from clear. Similarly, often disease traits appear to causally relate to other phenotypes, but GWAS is typically performed on the liability scale, hence the causal estimate reflects not the presence or absence of disease, but the underlying risk of disease. Again, interpretation of such associations can be problematic. 

A large proportion of the associations that were estimated used only a single instrumental variable. Methods are emerging to attempt to delineate between models of reverse cause, pleiotropy and multiple causal variants in the same region [@Zhu2016; @Richardson2017], but separating vertical from horizontal pleiotropy with a single instrument is not yet possible in the two-sample MR framework. Other problems can also manifest, for example frailty effects could induce associations for late-onset traits [@Noyce2017]; genetic variants could strongly relate to several phenotypes making it difficult to ascertain which of them is the causal exposure [@Burgess2014a]; and the measured feature for which genetic associations are known could relate in complicated ways to the biological entity that are truly causal [@DaveySmithHemani2014]. 

We also encounter a potential new problem in using machine learning approaches to infer the correct model for a particular dataset, namely, that the data is choosing the model. This is liable to increase type 1 error rates, even though we have attempted to separate the information used for optimisation from the information used to predict performance. Though MR-MoE does exhibit higher type 1 error rates than are desirable, they still remain amongst the lowest compared to all other MR methods that do not suffer from this issue.

Despite these limitations, the construction of a causal graph of 'everything versus everything' does have appeal. First, though causality is not guaranteed by MR, it can still be highly informative for confirming or negating specific hypotheses. Second, it offers new approaches to searching for novel putative associations. The potential to exploit GWAS summary data within the properties of graph databases to aid with both of these endeavours could be transformative in biological research.


## Figures

\newpage

![Simulations. a) Schematic of how GWAS with sufficient power can lead to the selection of instrumental variables that are invalid. We used arbitrary numbers of SNPs and confounders to simulate GWAS summary datasets. b) Any SNP that has a direct influence on the exposure, or an influence on a non-confounding intermediate variable, is considered a 'direct' effect. The y-axis shows the proportion of instruments selected for analysis due that are either direct associations with the exposure, instruments for the outcome (reverse), or instruments for confounding traits (confounder). The proportions are compared over a range of different exposure discovery sample sizes (x-axis) and using either the tophits approach (left) or the Steiger approach (right) for instrument selection. c) Top: The false discovery rates from null simulations for each of the 14 methods using either tophits, Steiger filtered variants, or variants that are known to be directly associated with the exposure (oracle, note that direct effects can still exhibit horizontal pleiotropy in these simulations). Bottom: The statistical power to detect true causal associations in the non-null simulations.](images/fig1.pdf)

\newpage

![Mixture of experts. a) Training. Datasets are simulated that have either null or non-null causal relationships, and MR is performed by each of the 28 available MR methods. In the toy datasets, the columns in black represent 53 metrics about each of the 67,000 training simulations. The columns in red are specific to each method, they represent how well that method performed in obtaining the correct answer for each of the datasets. Random forests are used to learn the parameter space of the 53 metrics in which a particular dataset is likely to perform well. Together, this creates 28 random forest decision trees, one for each method. b) Application. For a GWAS summary dataset, our objective is to choose the method most likely to return the correct causal estimate. Metrics are generated from the dataset and fed into each of the 28 random forest decision trees. This provides us with 28 performance predictions. Finally, we use the method for which the performance prediction is highest. ](images/fig2.pdf)

\newpage

![Performance of MoE against all other methods. a) The power for non-null datasets is plotted against the FDR for null datasets for each of the 28 methods, plus MoE. No single method achieved nominal FDR for these simulations. b) Calculating the area under the ROC curve from the values in (a) we plotted the performance in order from lowest to highest. Under the assumption of pervasive horizontal pleiotropy, the MoE approach is likely most effective than any other single method.](images/fig3.pdf)


\newpage

![Lookup of causal associations involving Years of Schooling. The arrows denote causal direction and the values on the arrows denote the causal effect estimate. Only those relationships are shown for which the $FDR < 0.05$.](images/fig4.png)

\newpage

## References

